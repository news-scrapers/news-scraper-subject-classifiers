{"id": "3923aa17-ab87-49ca-6d1e-b998f06b5835", "content": "Una inteligencia artificial responsable\n\nEl ser humano est\u00e1 perdiendo el control sobre las tecnolog\u00edas de la informaci\u00f3n y las comunicaciones que ha creado y la Inteligencia Artificial (IA) no es una excepci\u00f3n. Para no perder este control debemos orientar los avances de la IA al dise\u00f1o transparente de sistemas tecnol\u00f3gicos que sean compatibles con nuestros valores morales, sociales y culturales tales como la seguridad, la sostenibilidad, la democracia, la participaci\u00f3n, la seguridad, la transparencia, la rendici\u00f3n de cuentas y el surgimiento de ciertas propiedades y funciones\u2026 y las instituciones deben apoyar estos principios. El dise\u00f1o de los sistemas de IA se debe centrar en la eficiencia, la usabilidad, la flexibilidad, la resiliencia, la justicia, la dignidad, la felicidad, el bienestar, la seguridad, la salud, la empat\u00eda, la amistad, la solidaridad y la paz.\nLa IA est\u00e1 en nuestra vida m\u00e1s de lo que creemos; hacemos uso de ella pr\u00e1cticamente a diario y, muchas veces, casi sin ser conscientes de ello: cuando entramos en un aparcamiento y se reconoce la matr\u00edcula de nuestro veh\u00edculo; cuando utilizamos nuestro m\u00f3vil para encontrar la mejor ruta para llegar a un destino; al llamar por tel\u00e9fono y una m\u00e1quina interact\u00faa con nosotros para resolver nuestro problema; cuando hablamos con nuestro asistente virtual, cuando las plataformas de contenidos nos hacen recomendaciones que se ajustan a nuestras preferencias, cuando utilizamos traductores autom\u00e1ticos de lenguajes, cuando nuestro m\u00f3vil reconoce nuestra huella digital o nuestra cara, y as\u00ed podr\u00edamos seguir enumerando muchas m\u00e1s actividades cotidianas donde interviene la IA.\nLa IA es una de las tecnolog\u00edas m\u00e1s importantes del siglo XXI. Al igual que la m\u00e1quina de vapor o la electricidad en su momento produjeron grandes cambios en la sociedad, la IA est\u00e1 transformando el mundo. Las ventajas que se pueden obtener de la aplicaci\u00f3n de esta tecnolog\u00eda son muy prometedoras, ayudando a mejorar los diagn\u00f3sticos de im\u00e1genes m\u00e9dicas, permitir a los m\u00e9dicos desarrollar nuevas terapias para enfermedades; reducir el consumo de energ\u00eda optimizando los recursos y as\u00ed podr\u00edamos enumerar muchos de los retos que la IA puede abordar.\nPero no es oro todo lo que reluce. Son evidentes los beneficios que la sociedad puede obtener de los avances de la IA, pero tambi\u00e9n hay sombras. Los trabajadores temen perder su trabajo a causa de la automatizaci\u00f3n, los consumidores se preguntan qui\u00e9n es el responsable si un sistema basado en la IA tome una decisi\u00f3n equivocada, las peque\u00f1as empresas no saben c\u00f3mo aplicar la IA a su negocio, las nuevas empresas de IA no encuentran los recursos y el talento que necesitan en Europa, y la competencia internacional es m\u00e1s feroz que nunca.\nA medida que la Inteligencia Artificial se hace m\u00e1s sofisticada, comenzar\u00e1 a tomar decisiones \u2013o ayudar\u00e1 a tomarlas- que tienen un mayor impacto en las vidas de las personas. Esto plantea desaf\u00edos \u00e9ticos a medida que las personas se vayan adaptando al papel m\u00e1s amplio y prominente de la toma de decisiones automatizada en la sociedad.\nPensemos en este caso: un veh\u00edculo de conducci\u00f3n aut\u00f3noma al que, en un instante determinado, se le atraviesa un perro en su trayectoria y decide tomar la decisi\u00f3n de dar un giro brusco para no atropellarlo; como consecuencia de ello golpea a otro veh\u00edculo lo que da lugar a que se produzcan heridos graves, tanto entre los ocupantes del veh\u00edculo aut\u00f3nomo como entre los del veh\u00edculo golpeado. \u00bfQui\u00e9n es el responsable de este accidente? \u00bfEl perro? \u00bfEl due\u00f1o del perro? \u00bfEl constructor del autom\u00f3vil? \u00bfLos constructores de los dispositivos de sensorizaci\u00f3n y actuaci\u00f3n del autom\u00f3vil? \u00bfLos t\u00e9cnicos que han desarrollado el software que permite al autom\u00f3vil tomar la decisi\u00f3n? \u00bfEl propietario del autom\u00f3vil que ha personalizado el sistema de toma de decisiones para adaptarlo a sus preferencias? \u00bfLa administraci\u00f3n que ha autorizado la circulaci\u00f3n del veh\u00edculo? A medida que aumente el uso de la IA, ser\u00e1 m\u00e1s dif\u00edcil determinar la responsabilidad de las decisiones. Si se cometen errores que causan da\u00f1o, \u00bfqui\u00e9n debe asumir la responsabilidad?\nPara poder determinar la responsabilidad en la toma de decisiones de los sistemas de IA se requiere transparencia. Los sistemas de IA deben explicar sus acciones a los seres humanos para demostrar por qu\u00e9 se tom\u00f3 una decisi\u00f3n. La implantaci\u00f3n de los sistemas de IA da lugar a numerosas cuestiones sociales, econ\u00f3micas, pol\u00edticas, tecnol\u00f3gicas, legales, \u00e9ticas y filos\u00f3ficas. \u00bfDeber\u00edan los sistemas de IA ser tratados como entes \u00e9ticos? \u00bfPueden las m\u00e1quinas tomar decisiones morales? \u00bfCu\u00e1les son las consecuencias legales y \u00e9ticas de las tecnolog\u00edas de IA? \u00bfCu\u00e1les son las consecuencias de que las administraciones p\u00fablicas, las empresas y otras organizaciones tengan acceso a los datos y a las predicciones sobre el comportamiento de los ciudadanos? \u00bfC\u00f3mo pueden los valores morales, sociales y legales ser parte del proceso de dise\u00f1o de los sistemas de IA?\nPara hacer frente a estos retos y aprovechar al m\u00e1ximo las oportunidades que ofrece la IA surge la Inteligencia Artificial Responsable, una IA de confianza basada en valores \u00e9ticos y sociales con un enfoque centrado en el ser humano. Un principio clave es la \"\u00e9tica en el dise\u00f1o\", en virtud de la cual se aplicar\u00e1n principios \u00e9ticos y jur\u00eddicos, con los datos utilizados desde el inicio del proceso de dise\u00f1o. Al definir los requisitos de los sistemas de IA, tambi\u00e9n es importante tener en cuenta las interacciones con los seres humanos. Otro principio clave es la \"seguridad desde el dise\u00f1o\", seg\u00fan el cual la ciberseguridad, la protecci\u00f3n de las v\u00edctimas y la facilitaci\u00f3n de la aplicaci\u00f3n de la ley deben tenerse en cuenta desde el principio del proceso de dise\u00f1o.\nPara que la IA pueda cumplir sus expectativas, se requiere previsibilidad y confianza. El tratamiento previsible de las complejas cuestiones que plantea la IA, como la rendici\u00f3n de cuentas y los usos permitidos de los datos, fomentar\u00e1 su inversi\u00f3n y uso; el progreso de la IA requiere que los consumidores conf\u00eden en la tecnolog\u00eda y en la equidad, en c\u00f3mo se ven afectados por ella y c\u00f3mo se utilizan sus datos; un tratamiento predecible y transparente facilita esta confianza.\nNecesitamos un marco jur\u00eddico s\u00f3lido para abordar estas cuestiones, que son demasiado complejas o cambian con demasiada rapidez, para que la legislaci\u00f3n las aborde adecuadamente. Pero el proceso pol\u00edtico y legal por s\u00ed solo no ser\u00e1 suficiente. Para que la confianza florezca, un c\u00f3digo \u00e9tico para los cient\u00edficos de la IA es igualmente importante.\nLa IA Responsable no trata s\u00f3lo de crear reglas para gobernar las m\u00e1quinas inteligentes, que tambi\u00e9n, la misma tecnolog\u00eda debe permitir la regulaci\u00f3n autom\u00e1tica de sus aplicaciones: hay que regular los datos que se crean y comparten, hay que dar soluciones en una sociedad basada en datos. Las tecnolog\u00edas digitales y la ciencia de los datos se utilizan ahora para dar forma a nuestras sociedades, para constituir el tejido mismo de nuestra sociedad, a menudo obviando la toma de decisiones democr\u00e1tica y los hechos cient\u00edficos.\nPodemos destacar siete retos a los que la Inteligencia Artificial Responsable debe dar respuesta: Responsabilidad por los errores(debe quedar claro d\u00f3nde radica la responsabilidad cuando los sistemas cometen errores y han de rendir cuentas), Transparencia en la toma de decisiones (los sistemas de IA deben explicar sus acciones a los seres humanos), Trabajo (los sistemas de IA reemplazan a las personas en muchos trabajos tradicionales; debemos repensar el significado del trabajo), Evitar el sesgo (deben promoverse valores fundamentales como la igualdad, la diversidad y la ausencia de discriminaci\u00f3n como consecuencia de la aplicaci\u00f3n de la tecnolog\u00eda), Valores \u00e9ticos fundamentales (\u00bfcu\u00e1les ser\u00e1n los valores \u00e9ticos fundamentales de la IA?), Protecci\u00f3n de datos y propiedad intelectual (la propiedad intelectual debe reconocerse y sopesarse en relaci\u00f3n con la necesidad de utilizar los datos para fomentar la innovaci\u00f3n), Ciberseguridad (protecci\u00f3n contra la pirater\u00eda inform\u00e1tica a medida que los sistemas de IA asumen un papel m\u00e1s destacado en la sociedad).\nEl comportamiento de las personas est\u00e1 regulado por numerosas leyes, sin embargo, los algoritmos est\u00e1n sujetos a muy pocas regulaciones. Esto es inapropiado y peligroso, ya que los sistemas de IA interfieren cada vez m\u00e1s en nuestras vidas, a menudo sin nuestro conocimiento. Esto deber\u00eda estar controlado, aun trat\u00e1ndose de un servicio gratuito.\nUna nueva y prometedora etapa est\u00e1 llegando y la Inteligencia Artificial Responsable nos puede ayudar a recibirla.\nVicent Botti es catedr\u00e1tico del Instituto Valenciano de Investigaci\u00f3n en Inteligencia Artificial (VRAIN). Universitat Polit\u00e8cnica de Val\u00e8ncia\n NEWSLETTER \n Recibe el bolet\u00edn de Ciencia \nUna breve gu\u00eda para que el hombre moderno (o sea, t\u00fa) sepa c\u00f3mo regalar joyas estas navidades evitando compras fallidas de \u00faltima hora y triste desaciertos. Si ya no triunfas regalando, es porque no quieres", "date": "08/01/2019, 19:01:45", "tags": ["Opini\u00f3n", "Inteligencia artificial", "Computaci\u00f3n", "Telefon\u00eda m\u00f3vil multimedia", "Telefon\u00eda m\u00f3vil", "Empresas", "Inform\u00e1tica", "Tecnolog\u00edas movilidad", "Telefon\u00eda", "Econom\u00eda", "Tecnolog\u00eda", "Telecomunicaciones", "Industria", "Comunicaciones", "Ciencia"], "newspaper": "elpais"}