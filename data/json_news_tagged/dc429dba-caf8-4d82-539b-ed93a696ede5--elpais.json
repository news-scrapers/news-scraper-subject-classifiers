{"id": "dc429dba-caf8-4d82-539b-ed93a696ede5", "content": "Abran las cajas negras\n\nEn el Senado franc\u00e9s se est\u00e1 debatiendo estos d\u00edas si se debe exigir por ley que la Administraci\u00f3n explique los algoritmos que utiliza en sus aplicaciones. Miles de estudiantes se quejan de que la plataforma que gestiona su admisi\u00f3n en la ense\u00f1anza superior, Parcoursup, ha sido programada con criterios sesgados. Supuestamente, favorece a los estudiantes con m\u00e1s informaci\u00f3n y, en definitiva, con m\u00e1s recursos. Y, aunque hace dos a\u00f1os que la Ley Digital exige la transparencia algor\u00edtmica en Francia, esta no se da ni por parte del Gobierno ni de las empresas.\nOmnipresentes e invisibles, los algoritmos determinan cada vez m\u00e1s nuestro d\u00eda: qu\u00e9 pel\u00edculas nos propone Netflix o cu\u00e1nto nos cuesta una reserva de hotel. Gracias a ellos se pueden gestionar cantidades enormes de informaci\u00f3n de manera m\u00e1s eficiente. Pero tambi\u00e9n pueden terminar discriminando por c\u00f3mo han sido programados. Un ejemplo que da Marta Peirano en El enemigo conoce el sistema es el de David Dao, un pasajero al que sacaron a rastras de un avi\u00f3n en abril de 2017. Hab\u00eda pasado todos los controles de seguridad en el aeropuerto de Chicago y estaba esperando el despegue cuando las azafatas llegaron a echarle. Se neg\u00f3 y los agentes de seguridad terminaron sac\u00e1ndolo por la fuerza. United Airlines hab\u00eda vendido demasiados billetes y sobraba alguien. Un algoritmo hab\u00eda determinado que fuera Dao y no otro el expulsado. \u00c9l no era tan valioso para la aerol\u00ednea como un titular de la tarjeta de viajero frecuente. \u00bfUsaron tambi\u00e9n datos socioecon\u00f3micos, religiosos o raciales? Se desconoce, porque el algoritmo es secreto.\nLos sistemas de decisi\u00f3n algor\u00edtmica que tengan un impacto en los derechos de las personas deber\u00edan ser transparentes.\nProblema: la transparencia siempre suena bien como valor exigible, pero habr\u00e1 situaciones en las que no se pueda explicar un algoritmo. Para empezar, no es sencillo obligar a las empresas a poner su c\u00f3digo a disposici\u00f3n del p\u00fablico; ser\u00eda violar su propiedad intelectual y aniquilar la innovaci\u00f3n. Pero, adem\u00e1s, algunos son \u00e1rboles de decisi\u00f3n sencillos, basados en reglas ordenadas. Otros son redes neuronales que no controlan ni quienes los han programado. Sus autores solo pueden probarlos una y otra vez hasta que entienden que las m\u00e1quinas est\u00e1n haciendo lo que deben hacer.\nUna de las posibles soluciones es pedir que se rindan cuentas, no ante los ciudadanos, sino ante una autoridad independiente, quiz\u00e1 supranacional, sin \u00e1nimo de lucro y formada por expertos. Est\u00e1n naciendo iniciativas como OdiseIA en Espa\u00f1a para analizar el impacto de la inteligencia artificial y asesorar al sector p\u00fablico y privado. Pretenden crear un sello de calidad para quienes cumplan ciertos est\u00e1ndares de transparencia. Es el momento de poner la \u00e9tica en la agenda. Creer que por s\u00ed mismas las m\u00e1quinas van a tomar decisiones justas es el equivalente hoy al cl\u00e1sico error liberal de pensar que los mercados se regulan solos.\nPuedes seguir EL PA\u00cdS Opini\u00f3n en Facebook, Twitter o suscribirte aqu\u00ed a la Newsletter.\n NEWSLETTER \n Recibe el bolet\u00edn de Opini\u00f3n \nUna breve gu\u00eda para que el hombre moderno (o sea, t\u00fa) sepa c\u00f3mo regalar joyas estas navidades evitando compras fallidas de \u00faltima hora y triste desaciertos. Si ya no triunfas regalando, es porque no quieres\nINICIA SESI\u00d3N PARA SEGUIR LEYENDO\nSolo con tener una cuenta ya puedes leer este art\u00edculo, es gratis.\nGracias por leer EL PA\u00cdS\n\u00bfNo est\u00e1s registrado? Crea tu cuenta", "date": "09/21/2019, 19:01:45", "tags": ["Opini\u00f3n", "Inteligencia artificial", "Computaci\u00f3n", "Inform\u00e1tica", "Industria"], "newspaper": "elpais"}