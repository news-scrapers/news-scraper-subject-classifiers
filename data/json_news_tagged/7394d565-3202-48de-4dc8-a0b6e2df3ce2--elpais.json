{"id": "7394d565-3202-48de-4dc8-a0b6e2df3ce2", "content": "Los gigantes de internet se movilizan contra los v\u00eddeos falsos\n\nEl humorista estadounidense James Meskimen mira hacia la c\u00e1mara y empieza su n\u00famero. Imita las voces y los gestos de varios personajes famosos: John Malkovich, Colin Firth, Robert De Niro\u2026 Sin embargo, a medida que cambia de personaje su rostro tambi\u00e9n lo hace y en lugar de su cara aparece la de aquellos a los que imita: Arnold Schwarzenegger, George Bush o incluso Morgan Freeman. El espectacular resultado no se debe a las habilidades sobrehumanas de este imitador norteamericano, sino a su colaboraci\u00f3n con un popular creador de deepfakes. Los algoritmos para manipular videos son cada vez m\u00e1s accesibles y precisos y consiguen resultados tan espectaculares como el de Meskimen. Sin embargo, no todas las manipulaciones son tan l\u00fadicas y varios gigantes de internet creen que estos enga\u00f1os podr\u00edan utilizarse para manipular a la opini\u00f3n p\u00fablica en procesos de gran importancia social, como lo son unas elecciones, por lo que han empezado a invertir en m\u00e9todos para detectar este tipo de videos falsos.\nEl pasado mes de septiembre Google public\u00f3 una base de datos de c\u00f3digo abierto que contiene unos 3.000 v\u00eddeos manipulados, mientras que, pocas semanas antes, Facebook hab\u00eda anunciado que publicar\u00eda una similar a finales de este mismo a\u00f1o. Estas bases de datos servir\u00e1n para que varios proyectos de inteligencia artificial aprendan a identificar de forma autom\u00e1tica los videos falsos y poder poner as\u00ed coto a la propagaci\u00f3n de mentiras a trav\u00e9s de la red.\nLa situaci\u00f3n ha cambiado enormemente desde 2017, cuando un usuario de Reedit llamado Deepfakes public\u00f3 varios videos pornogr\u00e1ficos manipulados. Hasta entonces, el coste computacional de crear un video falso de cierta calidad era muy elevado, por lo que solo estaba al alcance de equipos profesionales. Sin embargo, \u201cel problema ha evolucionado mucho a lo largo del \u00faltimo a\u00f1o\u201d, explica el investigador de la Universidad T\u00e9cnica de Munich, Andreas Roessler, y \u201choy en d\u00eda, existen m\u00faltiples m\u00e9todos en l\u00ednea que permiten a cualquiera crear videos faciales manipulados\u201d.\nLa realizaci\u00f3n de un deepfake requiere normalmente de dos clips de v\u00eddeo que se fusionan haciendo uso de una t\u00e9cnica de inteligencia artificial denominada aprendizaje profundo o deep learning\nLa realizaci\u00f3n de un deepfake requiere normalmente de dos clips de v\u00eddeo que se fusionan haciendo uso de una t\u00e9cnica de inteligencia artificial denominada aprendizaje profundo o deep learning, de ah\u00ed el nombre de estos videos. Los algoritmos aprenden la apariencia de cada cara para pegar una sobre la otra, manteniendo los movimientos de ciertas partes, como las cejas, la boca o los ojos, pero intercambiando los rasgos.\nUno de los motivos que han facilitado la propagaci\u00f3n de este tipo de videos se encuentra en los avances tecnol\u00f3gicos desarrollados durante los \u00faltimos a\u00f1os, especialmente en el campo del reconocimiento facial. \"Estos m\u00e9todos son el fruto de la investigaci\u00f3n de la realidad virtual y aumentada y del hecho de que disponemos de m\u00e9todos cada vez m\u00e1s poderosos para analizar las caras\u201d, afirma Roessler.\nActualmente existen varios m\u00e9todos para detectar estos videos manipulados, pero la mayor\u00eda requieren la supervisi\u00f3n de un ser humano, lo que ralentiza mucho el proceso, as\u00ed que se est\u00e1n desarrollando varios proyectos cuyo objetivo es generar herramientas de detecci\u00f3n autom\u00e1tica y uno de ellos es FaceForensics, del que Roessler es uno de los principales responsables.\nCreado de forma conjunta por investigadores de la Universidad T\u00e9cnica de Munich y la Universidad Federico II de N\u00e1poles, los miembros de este proyecto han generado casi 1.000 v\u00eddeos falsos mediante cuatro m\u00e9todos comunes de manipulaci\u00f3n facial. La idea es que estos videos sirvan para entrenar una inteligencia artificial, tambi\u00e9n basada en aprendizaje profundo, para que aprenda a detectar los deepfakes sin intervenci\u00f3n humana. En esencia, es una batalla entre dos inteligencias artificiales, la que genera los videos manipulados y la que trata de detectarlos.\nSeg\u00fan Roessler, \u201cestos modelos de aprendizaje autom\u00e1tico han producido resultados superiores en comparaci\u00f3n con otros enfoques\u201d, sin embargo, aclara este investigador, \u201ctienen el inconveniente de que necesitamos proporcionar muchos datos para poder entrenarlos adecuadamente\u201d y ah\u00ed es donde entran en juego los gigantes de internet, que pueden generar bases de datos con miles de videos manipulados para ayudar a entrenar a estas nuevas herramientas.\nEste proyecto concreto recibe el apoyo directo de Google, que ha creado una base de datos de deepfakes trabajando con 28 actores con los que grabaron cientos de v\u00eddeos realizando diferentes acciones. Posteriormente, utilizaron diferentes modelos de generaci\u00f3n videos manipulados de c\u00f3digo abierto para crear aproximadamente los 3.000 videos que han a\u00f1adido a la base de datos de FaceForensics.\nTambi\u00e9n Facebook ha centrado su atenci\u00f3n en la detecci\u00f3n de estos videos manipulados y el mes pasado anunci\u00f3, junto con Microsoft, Amazon e investigadores de varias instituciones internacionales, el lanzamiento del Deepfake Detection Challenge, un proyecto que ofrecer\u00e1 recompensas en efectivo para los mejores m\u00e9todos de detecci\u00f3n autom\u00e1tica.\nLa gente ha manipulado im\u00e1genes desde que existe la fotograf\u00eda, pero ahora casi todo el mundo puede crear y distribuir im\u00e1genes falsas a una audiencia masiva\n\"La gente ha manipulado im\u00e1genes desde que existe la fotograf\u00eda, pero ahora casi todo el mundo puede crear y distribuir im\u00e1genes falsas a una audiencia masiva\u201d, asegura Antonio Torralba, miembro de este proyecto y director del laboratorio de inteligencia artificial IBM Watson en el Instituto Tecnol\u00f3gico de Massachusetts (MIT, por sus siglas en ingl\u00e9s). \"El objetivo de este concurso es construir sistemas de IA que puedan detectar las peque\u00f1as imperfecciones de una imagen manipulada y exponer as\u00ed la falsedad de estos videos\".\nSin embargo, estos m\u00e9todos est\u00e1n lejos de resolver el problema de fondo, ya que una vez que un m\u00e9todo de detecci\u00f3n ha conseguido identificar los peque\u00f1os errores de un video manipulado, el algoritmo de generaci\u00f3n puede ser actualizado para corregir dichas imperfecciones. Por este motivo, algunos investigadores sostienen que la lucha contra los deepfakes no se puede basar \u00fanicamente en medios t\u00e9cnicos, sino que tambi\u00e9n requerir\u00e1 medidas pol\u00edticas y sociales para limitar los incentivos que fomentan su creaci\u00f3n, un entorno en el que el papel de los gigantes de internet no est\u00e1 tan claro.\nA principios de este a\u00f1o, Facebook se neg\u00f3 a eliminar varios v\u00eddeos en los que la presidenta del Congreso de EEUU, la dem\u00f3crata Nancy Pelosi, parec\u00eda tener problemas de salud y, este mismo mes, hizo lo propio con un anuncio comprado por el equipo de campa\u00f1a de Trump con informaci\u00f3n falsa sobre el precandidato dem\u00f3crata Joe Biden. Estos hechos demuestran que, aunque la red social haya decidido invertir en la detecci\u00f3n autom\u00e1tica de videos manipulados, no tiene ninguna intenci\u00f3n de retirar las informaciones falsas que circulan por su plataforma.\n NEWSLETTER \n Recibe la mejor informaci\u00f3n en tu bandeja de entrada \nUna breve gu\u00eda para que el hombre moderno (o sea, t\u00fa) sepa c\u00f3mo regalar joyas estas navidades evitando compras fallidas de \u00faltima hora y triste desaciertos. Si ya no triunfas regalando, es porque no quieres", "date": "10/29/2019, 20:01:45", "tags": ["Fake news", "Manipulaci\u00f3n informativa", "V\u00eddeo", "Soportes audiovisuales", "Audiovisuales", "Producci\u00f3n audiovisual", "Medios comunicaci\u00f3n", "Tecnolog\u00eda", "Comunicaci\u00f3n", "Ciencia"], "newspaper": "elpais"}