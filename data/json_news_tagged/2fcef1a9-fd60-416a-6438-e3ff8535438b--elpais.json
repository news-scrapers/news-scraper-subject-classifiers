{"id": "2fcef1a9-fd60-416a-6438-e3ff8535438b", "content": "Privacidad y datos en un mundo de algoritmos: riesgos y l\u00edmites\n\nUn esc\u00e1ner facial en el aeropuerto no reconoci\u00f3 la diferencia entre Osama bin Laden y Winona Ryder. Huellas digitales alteradas ayudan a una mujer a burlar los controles fronterizos. Una empresa es multada por compartir datos de millones de usuarios sin consentimiento. Un algoritmo discrimina contrataci\u00f3n de mujeres.\u00a0Seguramente estos titulares recuerden a alguna noticia similar le\u00edda antes.\nPor un lado, sabemos que los datos son la d\u00ednamo de la econom\u00eda digital. Compartirlos entre diferentes proveedores \u2014p\u00fablicos y privados\u2014 de forma interoperable promete revolucionar servicios que est\u00e9n hechos a la medida de las necesidades de cada persona y minimizar el margen de error de forma costo-eficiente. En servicios sociales, por ejemplo, ha permitido hacer m\u00e1s eficiente la asignaci\u00f3n de prestaciones a los beneficiarios que verdaderamente lo necesitan, as\u00ed como que la persona tenga mejor control sobre el cuidado de su salud o su ahorro para el retiro.\nSin embargo, es frecuente que las personas no tengan idea alguna de c\u00f3mo su perfil, geolocalizaci\u00f3n, rostro o historial de visitas en l\u00ednea terminan en manos de proveedores que \u201cconocen sus intereses\u201d. Y es que, aunque aceptar los t\u00e9rminos de privacidad y de compartir datos sea una precondici\u00f3n normalizada para descargar una aplicaci\u00f3n o visitar un sitio, estos suelen explicarse en un lenguaje complejo de entender entre audiencias no t\u00e9cnicas.\nEn el campo de la biometr\u00eda, poder identificar a una persona sin su autorizaci\u00f3n, a trav\u00e9s de su tono de voz, la forma en la que escribe o incluso su forma de caminar, supone riesgos considerables sobre derechos fundamentales como la privacidad y potencial discriminaci\u00f3n algor\u00edtmica. \u201cCuando tu cuerpo es tu identidad, este puede tambi\u00e9n delatarte o revelar cosas que preferir\u00edas no compartir\u201d, se\u00f1ala la eticista Gemma Galdon Clavel.\nAdicionalmente, hay un riesgo de seguridad, si los datos sensibles son vulnerados sin candados de encriptaci\u00f3n. As\u00ed lo muestra un reciente caso que expuso los datos de huellas digitales, reconocimiento facial, nombres de usuarios y contrase\u00f1as de m\u00e1s de un mill\u00f3n de personas, dentro de una base de datos p\u00fablica en Reino Unido. De acuerdo con el medio de comunicaci\u00f3n, la exposici\u00f3n responde a la falta de protecci\u00f3n y encriptaci\u00f3n de la base de datos por la empresa que la resguardaba.\nPor eso, el Banco Interamericano de Desarrollo (BID) dedic\u00f3 una nueva serie de publicaciones para analizar el avance del marco regulatorio en \u00e9tica de datos, advertir cu\u00e1les son los riesgos de usar tecnolog\u00edas como la inteligencia artificial (IA) con base en datos personales y proponer medidas para mitigarlos. Su edici\u00f3n m\u00e1s reciente permite entender a trav\u00e9s de un c\u00f3mic, cu\u00e1les son los l\u00edmites de la biometr\u00eda y acciones de contrapeso.\nCuando tu cuerpo es tu identidad, este puede tambi\u00e9n delatarte o revelar cosas que preferir\u00edas no compartir\nPara Galdon Clavell, la aplicaci\u00f3n de tecnolog\u00edas en datos biom\u00e9tricos es una opci\u00f3n que debe usarse con cautela. Una alternativa, sugiere, es mejorar la interoperabilidad y calidad de los datos usados, para poder verificar informaci\u00f3n entre instituciones sin tener que acceder a datos personales. Alternativamente, recomienda utilizar la verificaci\u00f3n de identidad con cadenas de bloques (blockchain) o bien combinar identificadores externos, a trav\u00e9s de contrase\u00f1as.\nEste tipo de pasos tambi\u00e9n ayuda a generar mayor confianza ciudadana en la era digital, y esto aplica tanto a servicios p\u00fablicos como privados. De acuerdo con Bloomberg, el 83% de los ejecutivos est\u00e1n de acuerdo que la confianza es la piedra angular de la econom\u00eda digital. A medida que los usuarios y prestadores de servicios toman consciencia de los riesgos y soluciones para un uso responsable de datos, aumentan los incentivos para crear principios y cumplir reglas.\nEn Am\u00e9rica Latina y el Caribe, algunas organizaciones y pa\u00edses, como M\u00e9xico, ya cuentan con lineamientos sobre la privacidad y el uso de inteligencia artificial. Pero podemos y debemos hacer mucho m\u00e1s.\nRespecto al marco regulatorio, la referencia global es el Reglamento de Protecci\u00f3n de Datos de la Uni\u00f3n Europea (GDPR, por sus siglas en ingl\u00e9s). Esta norma establece que antes de procesar cualquier dato personal, un negocio debe preguntar expl\u00edcitamente el permiso de la persona, en un lenguaje claro y con el consentimiento para un prop\u00f3sito espec\u00edfico. Esta premisa ha abierto, en cierto sentido, una caja de Pandora tanto para reguladores como para empresas, que \u00faltimamente contribuir\u00e1 a un sistema de manejo de datos fortalecido y con epicentro en la persona.\nEn tan solo un a\u00f1o de implementaci\u00f3n del GDPR, se han registrado 90.000 notificaciones de violaciones de datos y 145.000 quejas. Adem\u00e1s, 100 organizaciones han pagado sanciones por incumplimiento y Francia mult\u00f3 a Google con 50 millones de euros, por recolectar datos sin el adecuado nivel de trasparencia sobre c\u00f3mo se usar\u00edan esos datos.\nCon el objetivo de acelerar la adopci\u00f3n responsable de la IA con impacto social, por parte de los gobiernos de Am\u00e9rica Latina y el Caribe, el Sector Social del BID est\u00e1 preparando una iniciativa regional, conocida como fAIr LAC. Tambi\u00e9n elabor\u00f3 un marco conceptual y metodol\u00f3gico para apoyar a los pa\u00edses a facilitar la interoperabilidad de datos en sus plataformas p\u00fablicas de forma \u00e9tica, que les permita ser m\u00e1s efectivos en la toma de decisiones y elevar la calidad de los servicios sociales prestados.\nCompartir datos se ha convertido en una pr\u00e1ctica esencial de la econom\u00eda digital. Las personas dejamos un halo cr\u00f3nico de datos digitales, aun sin darnos cuenta. Pero hay riesgos que requieren la atenci\u00f3n de tomadores de decisi\u00f3n en cualquier organizaci\u00f3n que est\u00e9 involucrada con manejo y an\u00e1lisis de datos compartidos, sobre todo al tratarse de datos privados o de identificaci\u00f3n biom\u00e9trica. Mientras que el futuro apunta a un uso de informaci\u00f3n m\u00e1s regulado, deja la tarea de generar una cultura de responsabilidad que sea inherente a su gesti\u00f3n.\nPuedes seguir a PLANETA FUTURO en Twitter y Facebook e Instagram, y suscribirte aqu\u00ed a nuestra newsletter.\n NEWSLETTER \n Recibe el bolet\u00edn de Planeta Futuro \nUna breve gu\u00eda para que el hombre moderno (o sea, t\u00fa) sepa c\u00f3mo regalar joyas estas navidades evitando compras fallidas de \u00faltima hora y triste desaciertos. Si ya no triunfas regalando, es porque no quieres", "date": "09/10/2019, 19:01:45", "tags": ["Big data", "Opini\u00f3n", "Anal\u00edtica datos", "Bases datos", "Tecnolog\u00edas informaci\u00f3n", "Computaci\u00f3n", "Latinoam\u00e9rica", "Inform\u00e1tica", "Am\u00e9rica", "Industria", "Tecnolog\u00eda", "Telecomunicaciones", "Comunicaciones", "Ciencia"], "newspaper": "elpais"}