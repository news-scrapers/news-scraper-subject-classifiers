{"id": "3f2d2b6b-3e1d-47bb-57db-dc1b5025916d", "content": "YouTube investiga c\u00f3mo mejorar recomendaciones y aumentar el tiempo de conexi\u00f3n\n\n\u201c\u00bfCu\u00e1nto podr\u00edan haber mejorado nuestros \u00faltimos momentos juntos si no fuera por los delirios inducidos por YouTube?\u201d. El pasado mes de septiembre el hijo de un cient\u00edfico retirado de 80 a\u00f1os cont\u00f3 c\u00f3mo su padre su padre se sumergi\u00f3 en una espiral t\u00f3xica de v\u00eddeos durante sus \u00faltimos a\u00f1os. Lo hizo a trav\u00e9s de una campa\u00f1a de la Fundaci\u00f3n Mozilla, creada para concienciar sobre los problemas generados por el algoritmo de recomendaciones de esta popular plataforma de v\u00eddeos. Ahora, varios investigadores de la compa\u00f1\u00eda Google, propietaria de la plataforma audiovisual, han propuesto una modificaci\u00f3n de este algoritmo que mejorar\u00eda las recomendaciones y aumentar\u00eda el tiempo que los usuarios permanecen conectados.\nLa inteligencia artificial controla gran parte de la informaci\u00f3n que se consume hoy en d\u00eda en Internet. Los algoritmos creados por las distintas plataformas \u201cobservan la actividad de los usuarios e infieren cosas que le puedan interesar y se las proponen\u201d, explica Pablo Castells, profesor titular de la Escuela Polit\u00e9cnica Superior de la Universidad Aut\u00f3noma de Madrid. \u201cHay muchas maneras de hacerlo, desde la m\u00e1s trivial, como es ofrecer simplemente lo m\u00e1s popular, hasta formas m\u00e1s complejas que implican fijarse en el comportamiento de cada usuario individual\u201d.\nEn el caso de YouTube, la plataforma hace una primera lista de recomendaciones con varios cientos de v\u00eddeos relacionados con el que est\u00e1 viendo el usuario y luego va refinando dicha lista teniendo en cuenta sus clics, gustos y otras interacciones. El resultado es que de los mil millones de horas que se ven cada d\u00eda en esta plataforma, un 70% corresponde a v\u00eddeos recomendados por el algoritmo.\nLas distintas plataformas trabajan por mejorar este sistema, hacerlo a\u00fan m\u00e1s preciso y mantener durante unos minutos m\u00e1s a los usuarios delante de la pantalla y esto es lo que parece haber conseguido un equipo de investigadores de YouTube, seg\u00fan un art\u00edculo publicado en la revista ACM Digital Library. \u201cDemostramos que nuestras propuestas pueden conducir a mejoras sustanciales en la calidad de las recomendaciones\u201d, afirma el estudio.\nPara refinar las recomendaciones, los investigadores probaron a dar m\u00e1s importancia a los v\u00eddeos que se encuentran en la parte baja del listado, ya que se entiende que si el usuario ha hecho clic en esos v\u00eddeos es porque ha dedicado cierto tiempo a buscarlo. Gracias a esta modificaci\u00f3n los desarrollares del nuevo algoritmo aseguran que han conseguido \u201cmejoras sustanciales tanto en las m\u00e9tricas de compromiso como en las de satisfacci\u00f3n\u201d.\n\u201cEs una forma inteligente de abordar el problema\u201d, asegura Castells, \u201cya que sabemos que hay zonas de la pantalla que est\u00e1n m\u00e1s expuestas, por lo que conseguir un clic en esa zona tiene menos m\u00e9rito que el que se consigue en un elemento que est\u00e1 m\u00e1s escondido\u201d.\nSin embargo, este tipo modificaci\u00f3n sigue sin resolver uno de los grandes problemas que poseen estos algoritmos. Debido a que el sistema est\u00e1 optimizado para que los usuarios sigan viendo v\u00eddeos, \u00e9ste tiende a ofrecer recomendaciones que refuerzan los gustos o creencias del usuario, lo que puede crear una experiencia que excluya otras opiniones y estimule la generaci\u00f3n de lo que se conoce como c\u00e1maras de eco.\nEn este sentido, una investigaci\u00f3n de Google sobre el impacto de los sistemas de recomendaci\u00f3n, publicada a principios de este a\u00f1o, concluy\u00f3 que \"los bucles de retroalimentaci\u00f3n en los sistemas de recomendaci\u00f3n pueden dar lugar a c\u00e1maras de eco', lo que puede reducir la exposici\u00f3n de un usuario al contenido y, en \u00faltima instancia, cambiar su visi\u00f3n del mundo\".\nLos algoritmos creados por las distintas plataformas \u201cobservan la actividad de los usuarios e infieren cosas que le puedan interesar y se las proponen\u201d, explica Pablo Castells, profesor titular de la Escuela Polit\u00e9cnica Superior de la Universidad Aut\u00f3noma de Madrid\nTambi\u00e9n diversos estudios realizados en los \u00faltimos a\u00f1os, incluyendo un experimento desarrollado por periodistas de EL PA\u00cdS, han mostrado que el algoritmo suele recompensar los v\u00eddeos m\u00e1s extremos y controvertidos, aunque est\u00e9n repletos de bulos. \u201cHace tres a\u00f1os, mi exesposa, que padece problemas mentales, comenz\u00f3 a ver v\u00eddeos de teor\u00edas de la conspiraci\u00f3n y se los crey\u00f3 todos. YouTube no dej\u00f3 de alimentar su paranoia, miedos y ansiedades con v\u00eddeos, uno tras otro\u201d, afirma otro de los testimonios recopilados por la Fundaci\u00f3n Mozilla.\n\u201cEn la comunidad de algoritmos de recomendaci\u00f3n hay una preocupaci\u00f3n creciente en este sentido y cada vez hay m\u00e1s esfuerzos para promover una recomendaci\u00f3n responsable\u201d, asegura Castells. Seg\u00fan este especialista, hay que tener en cuenta que \u201clos objetivos del usuario y de las empresas no est\u00e1n necesariamente alineados, ya que la empresa necesita que el usuario est\u00e9 contento, pero de una manera que sea rentable y eso se consigue si el usuario est\u00e1 m\u00e1s tiempo conectado\u201d. El problema, asegura este investigador, \u201ces que el algoritmo no sabe cu\u00e1ndo el usuario est\u00e1 contento y cu\u00e1ndo ha entrado en un modo compulsivo\".\nEl algoritmo tambi\u00e9n ha sido cuestionado por su falta de idoneidad a la hora de ofrecer contenidos infantiles. Seg\u00fan un estudio publicado este mismo a\u00f1o en arXiv (un repositorio de art\u00edculos cient\u00edficos que no son revisados por pares), \u201chay un 45% de probabilidad de que un ni\u00f1o peque\u00f1o que sigue las recomendaciones de YouTube encuentre un v\u00eddeo inapropiado en menos de 10 clics\u201d.\nLos autores de este estudio aseguran que el problema se encuentra en el hecho de que ciertos v\u00eddeos para adultos utilizan contenidos de v\u00eddeos infantiles y el algoritmo no los diferencia. Ejemplos hay miles dentro de la plataforma, desde dibujos en los que Mickey Mouse es atropellado por un coche, hasta otros en los que Peppa Pig aparece comi\u00e9ndose a su padre.\nLa soluci\u00f3n, seg\u00fan Castells, \u201cpasar\u00eda por no ofrecer contenidos simplemente bas\u00e1ndonos en el volumen de respuesta, sino haciendo algo m\u00e1s cualitativo, identificando tipos de contenido\u201d. Sin embargo, este inform\u00e1tico advierte no solo de la complejidad t\u00e9cnica del problema, sino del \u201cdilema \u00e9tico que supone decidir qu\u00e9 contenido es marcado como inapropiado\u201d.\nLos problemas generados por estos algoritmos han llevado a Mozilla, una organizaci\u00f3n sin \u00e1nimo de lucro dedicada al software libre, a crear una campa\u00f1a para alertar sobre ello. Gracias a esta iniciativa se han recogido cientos de testimonios de personas que se han visto afectadas por estas recomendaciones o que han visto como alg\u00fan ser querido se sumerg\u00eda en la espiral t\u00f3xica de YouTube. \u201cEs triste y frustrante ver como una persona querida se hunde cada vez m\u00e1s en este tipo de influencia oscura, negativa y da\u00f1ina\u201d, se lamenta uno de ellos.\n NEWSLETTER \n Recibe la mejor informaci\u00f3n en tu bandeja de entrada \nUna breve gu\u00eda para que el hombre moderno (o sea, t\u00fa) sepa c\u00f3mo regalar joyas estas navidades evitando compras fallidas de \u00faltima hora y triste desaciertos. Si ya no triunfas regalando, es porque no quieres", "date": "11/04/2019, 20:01:45", "tags": ["Algoritmos computacionales", "Youtube", "Redes sociales", "Computaci\u00f3n", "Empresas", "Internet", "Televisi\u00f3n", "Inform\u00e1tica", "Telecomunicaciones", "Econom\u00eda", "Tecnolog\u00eda", "Medios comunicaci\u00f3n", "Industria", "Comunicaciones", "Comunicaci\u00f3n", "Ciencia"], "newspaper": "elpais"}