{"id": "95c85652-7195-4f11-4f95-c9aa6e40e44b", "content": "La nueva ola de la desinformaci\u00f3n: la irrupci\u00f3n de los \u2018deepfakes\u2019\n\nEn mayo de este mismo a\u00f1o, la dem\u00f3crata Nancy Pelosi, presidente de la C\u00e1mara de Representantes estadounidense, dio una conferencia en el Center of American Progress. Unos d\u00edas m\u00e1s tarde, unas im\u00e1genes suyas hablando en esa conferencia con la apariencia de estar afectada por alg\u00fan tipo de sustancia, se hicieron virales. Incluso el presidente, Donald Trump, no pudo resistirse a difundirlas.\nDe alguna manera con este v\u00eddeo se daba la bienvenida a otra dimensi\u00f3n nunca vista de la desinformaci\u00f3n pol\u00edtica, un v\u00eddeo manipulado que parece real pero no lo es, lo que ha venido a bautizarse como deepfake.\nUn deepfake es un tipo de mediafake, un v\u00eddeo de una persona haciendo algo que nunca ha hecho o incluso que nunca ha dicho. Hay varios tipos de mediafakes, siendo un deepkafe el m\u00e1s sofisticado de todos: un modelo computacional basado en tecnolog\u00eda deep learning (inteligencia artificial) cuyas im\u00e1genes han sido generadas matem\u00e1ticamente v\u00eda algoritmos a partir de fotos y v\u00eddeos de la persona a la que se quiere recrear.\nAunque los primeros deepfakes fueron creados hace unos cinco a\u00f1os, el t\u00e9rmino no fue acu\u00f1ado hasta 2017 en la comunidad Reddit, populariz\u00e1ndose paulatinamente desde entonces. Con el avance y la progresi\u00f3n sobre todo en el campo de la inteligencia artificial, no est\u00e1 siendo hasta este a\u00f1o donde por primera vez nos encontramos una escala importante en la difusi\u00f3n de v\u00eddeos con im\u00e1genes que, a simple vista, no podr\u00edamos ser capaces en discernir su autenticidad.\u00a0\nNos encontramos ante la difusi\u00f3n de v\u00eddeos con im\u00e1genes que, a simple vista, no podr\u00edamos ser capaces en discernir su autenticidad\nLa imparable democratizaci\u00f3n de la tecnolog\u00eda ha permitido que cualquier persona con acceso a cualquier programa o app de edici\u00f3n pueda manipular o alterar una foto o v\u00eddeo. Pero los deepfakes suben un pelda\u00f1o m\u00e1s en este tipo de manipulaci\u00f3n por la perfecci\u00f3n alcanzada, y pueden convertirse adem\u00e1s de, en una peligrosa arma pol\u00edtica usada para manipular la opini\u00f3n p\u00fablica o desestabilizar los sistemas democr\u00e1ticos, aunque tambi\u00e9n en un peligroso instrumento que puede afectar a la integridad de otro tipo de perfiles m\u00e1s an\u00f3nimos: como arma de revenge porn o para un uso malicioso en el terreno empresarial.\nPor ello, la irrupci\u00f3n a escala de esta tecnolog\u00eda, adem\u00e1s de alarmante, supone retos relevantes para todos. Es una nueva forma de manipulaci\u00f3n desconocida a la que tendremos que enfrentarnos. Como si de un juego se tratara, a partir de ahora, nada de lo que veremos en redes podremos darlo por cierto. Una nueva realidad para la industria de la informaci\u00f3n.\u00a0\nLa preocupaci\u00f3n es importante, sobre todo para los gigantes tech. Es por eso que algunos de ellos ya han comenzando a tomar medidas y est\u00e9n lanzando herramientas que posibiliten el desarrollo de aplicaciones para combatir lo que entienden puede ser su pr\u00f3ximo problema.\nGoogle ha liberado algunos de sus datasets de deepfakes que ellos mismos han construido para que investigadores puedan dise\u00f1ar herramientas para su detecci\u00f3n. Con este mismo fin Facebook, junto con Microsoft, MIT, Berkeley y otras instituciones acad\u00e9micas acaba de lanzar un \u2018Deepfake Detection Challenge (DFDC)\u2019. Adem\u00e1s de empresas privadas, la norteamericana DARPA a trav\u00e9s de su programa MediFor (Media Forensics) igualmente apoya con varias iniciativas c\u00f3mo combatir esta nueva oleada de im\u00e1genes sint\u00e9ticas.\u00a0\nA pesar de la amenaza impl\u00edcita de confusi\u00f3n de la realidad y estado de desinformaci\u00f3n generalizada, hay una buena noticia y es que no todo el mundo puede acceder, de momento, a este tipo de tecnolog\u00eda, ya que se requieren conocimientos computacionales hiperespecializados. Son \u00fanicamente los cient\u00edficos de datos expertos en deep learning los que son capaces de generar los algoritmos que los crean.\u00a0\nPero no debemos olvidar que la comunidad cient\u00edfica global distribuye el conocimiento en conferencias y plataformas online donde divulgan los avances de manera abierta. A este respecto, seg\u00fan Deeptrace, en 2018 fueron presentados 902 papers con avances en GAN (Generative Adversarial Networks), tecnolog\u00eda generada en 2014 y clave en la generaci\u00f3n de deepfakes, frente a los aproximadamente 100 de 2016, evidenciando as\u00ed un imparable inter\u00e9s creciente.\u00a0\nEn 2018 hab\u00eda, seg\u00fan Diffbot, 720.325 profesionales cualificados en el mundo con conocimientos y habilidades en inteligencia artificial (en Estados Unidos algo m\u00e1s del 30%), personas que construyen nuestro futuro, y no sabemos si con el grado de responsabilidad que esto requiere, a pesar de las buenas intenciones.\u00a0\nAs\u00ed pues, y pesar de la hiperespecializaci\u00f3n requerida, nunca se sabe qu\u00e9 equipo puede estar trabajando para la misi\u00f3n equivocada. Cobra m\u00e1s importancia que nunca, as\u00ed, la necesidad de crear principios \u00e9ticos universales y c\u00f3digos de conductas estandarizados, independientemente de la organizaci\u00f3n en la que los cient\u00edficos desempe\u00f1en su labor.\u00a0\nEs posible que desaparezca nuestra capacidad de discernir si es verdad aquello que vemos. Los deepfakes son solo algunos de los riesgos asociados a la vor\u00e1gine tecnol\u00f3gica actual. Seremos m\u00e1s dist\u00f3picos, pero alguien sabr\u00e1 sacarle partido, o en palabras de George Orwell, \"control de realidad, lo llamaron\".\u00a0\nSonia Pacheco es directora del congreso DES | Digital Enterprise Show.\u00a0\u00a0\n NEWSLETTER \n Recibe la mejor informaci\u00f3n en tu bandeja de entrada \nUna breve gu\u00eda para que el hombre moderno (o sea, t\u00fa) sepa c\u00f3mo regalar joyas estas navidades evitando compras fallidas de \u00faltima hora y triste desaciertos. Si ya no triunfas regalando, es porque no quieres\nINICIA SESI\u00d3N PARA SEGUIR LEYENDO\nSolo con tener una cuenta ya puedes leer este art\u00edculo, es gratis.\nGracias por leer EL PA\u00cdS\n\u00bfNo est\u00e1s registrado? Crea tu cuenta", "date": "10/01/2019, 19:01:45", "tags": ["Fake news", "Manipulaci\u00f3n informativa", "Inteligencia artificial", "Computaci\u00f3n", "Inform\u00e1tica", "Medios comunicaci\u00f3n", "Comunicaci\u00f3n", "Industria"], "newspaper": "elpais"}