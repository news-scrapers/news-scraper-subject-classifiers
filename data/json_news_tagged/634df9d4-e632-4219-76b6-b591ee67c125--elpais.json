{"id": "634df9d4-e632-4219-76b6-b591ee67c125", "content": "Por qu\u00e9 la falta de diversidad es un lastre para la inteligencia artificial\n\nLos sistemas de Inteligencia Artificial (IA) son cada vez m\u00e1s listos y derrotan a campeones del mundo en juegos como\u00a0Go, identifican tumores en pruebas m\u00e9dicas mejor que los radi\u00f3logos humanos y aumentan la eficacia de los centros de datos hambrientos de electricidad. Algunos economistas comparan el potencial transformador de la IA con otras \u201ctecnolog\u00edas de uso general\u201d como la m\u00e1quina de vapor, la electricidad o el transistor.\nPero los sistemas de IA actuales distan de ser perfectos. Tienden a reflejar los prejuicios de los datos que se utilizan para entrenarlos y a estropearse cuando se enfrentan a situaciones inesperadas. Se les puede enga\u00f1ar, como hemos visto en el caso de las controversias que rodean la informaci\u00f3n falsa en las redes sociales, el contenido violento publicado en Youtube, o el famoso caso de Tay, el chatbot de Microsoft, que fue manipulado para hacer declaraciones sexistas en cuesti\u00f3n de horas.\n\u00bfRealmente queremos transformar estas fr\u00e1giles tecnolog\u00edas propensas a los prejuicios en la piedra angular de la econom\u00eda del ma\u00f1ana?\nUna forma de minimizar los riesgos de la IA es aumentar la diversidad de los equipos implicados en su desarrollo. Como indica la investigaci\u00f3n sobre toma de decisiones colectiva y creatividad, los grupos que son cognitivamente m\u00e1s diversos tienden a tomar mejores decisiones. Desgraciadamente, este no es ni de lejos el caso de la comunidad que actualmente est\u00e1 desarrollando sistemas de IA. Y la falta de diversidad de g\u00e9nero es una dimensi\u00f3n importante (aunque no la \u00fanica) de esto.\nUn an\u00e1lisis publicado este a\u00f1o por el AI Now Institute revel\u00f3 que menos del 20% de los investigadores que solicitan participar en prestigiosas conferencias sobre IA son mujeres, y que estas representan solo una cuarta parte de los estudiantes universitarios de IA en Stanford y en la Universidad de California en Berkeley.\nLos autores afirmaban que esta falta de diversidad de g\u00e9nero da lugar a fallos de IA que \u00fanicamente afectan a las mujeres, como un sistema de contrataci\u00f3n de Amazon que discriminaba a los solicitantes de trabajo con nombres femeninos.\nNuestro reciente informe Diversidad de g\u00e9nero en la investigaci\u00f3n sobre IA, incluye un an\u00e1lisis de big data de 1,5 millones de trabajos de arXiv, una p\u00e1gina web de prepublicaciones que la comunidad de la IA utiliza muy a menudo para difundir su trabajo.\nNuestro an\u00e1lisis confirma la idea de que hay una crisis de diversidad de g\u00e9nero en la investigaci\u00f3n sobre IA. Solo el 13,8% de los autores de IA en arXiv son mujeres y, en t\u00e9rminos relativos, la proporci\u00f3n de trabajos de IA de los cuales es coautora al menos una mujer no ha mejorado desde la d\u00e9cada de los noventa\nAnalizamos el texto de res\u00famenes para determinar cu\u00e1les aplican t\u00e9cnicas de IA, dedujimos el g\u00e9nero de los autores a partir de sus nombres y estudiamos los niveles de diversidad de g\u00e9nero en la IA y su evoluci\u00f3n en el tiempo. Tambi\u00e9n comparamos la situaci\u00f3n en diversos campos de investigaci\u00f3n y pa\u00edses, y las diferencias en el lenguaje entre los trabajos con coautores femeninos y los trabajos con autores solo masculinos.\nNuestro an\u00e1lisis confirma la idea de que hay una crisis de diversidad de g\u00e9nero en la investigaci\u00f3n sobre IA. Solo el 13,8% de los autores de IA en arXiv son mujeres y, en t\u00e9rminos relativos, la proporci\u00f3n de trabajos de IA de los cuales es coautora al menos una mujer no ha mejorado desde la d\u00e9cada de los noventa.\nHay diferencias significativas entre pa\u00edses y campos de investigaci\u00f3n. Encontramos una mayor representaci\u00f3n femenina en la investigaci\u00f3n sobre IA en Holanda, Noruega y Dinamarca, y una representaci\u00f3n menor en Jap\u00f3n y Singapur. Tambi\u00e9n encontramos que es m\u00e1s probable que las mujeres que trabajan en f\u00edsica, educaci\u00f3n, biolog\u00eda y aspectos sociales de la inform\u00e1tica publiquen trabajos sobre IA frente a las que trabajan en inform\u00e1tica o matem\u00e1ticas.\nAdem\u00e1s de medir la diversidad de g\u00e9nero del personal investigador de la IA, tambi\u00e9n exploramos las diferencias sem\u00e1nticas entre trabajos de investigaci\u00f3n con y sin participaci\u00f3n femenina. Probamos la hip\u00f3tesis seg\u00fan la cual los equipos de investigaci\u00f3n con m\u00e1s diversidad de g\u00e9nero tienden a aumentar la variedad de problemas y temas que se tienen consideraci\u00f3n en la investigaci\u00f3n sobre IA, lo cual hace que sus resultados sean potencialmente m\u00e1s inclusivos.\nPara hacerlo, medimos la \u201cfirma sem\u00e1ntica\u201d de cada trabajo utilizando una t\u00e9cnica de aprendizaje de las m\u00e1quinas llamada word embeddings (mapeo de palabras) y comparamos las firmas de los trabajos en los cuales al menos un autor era una mujer con las de trabajos sin ninguna autora.\nEste an\u00e1lisis, que se centra en el campo del Aprendizaje de las M\u00e1quinas y los Aspectos Sociales de la Inform\u00e1tica en Reino Unido, mostraba diferencias significativas entre los grupos. En concreto, descubrimos que los trabajos con al menos una coautora tienden a ser m\u00e1s pr\u00e1cticos y sensibilizados socialmente, y en ellos t\u00e9rminos como \u201cjusticia\u201d, \u201cmovilidad humana\u201d, \u201cmental\u201d, \u201cg\u00e9nero\u201d y \u201cpersonalidad\u201d desempe\u00f1an un papel clave. La diferencia entre los dos grupos es coherente con la idea de que la diversidad cognitiva tiene un impacto en la investigaci\u00f3n producida e indica que da lugar a un mayor compromiso con las cuestiones sociales.\nEntonces, \u00bfc\u00f3mo se explica esta persistente brecha de g\u00e9nero en la IA y qu\u00e9 podemos hacer al respecto?\nLa investigaci\u00f3n muestra que la falta de diversidad de g\u00e9nero entre los trabajadores de la ciencia, la tecnolog\u00eda, la ingenier\u00eda y las matem\u00e1ticas (STEM, seg\u00fan sus siglas en ingl\u00e9s) no es producto de un solo factor: los estereotipos y la discriminaci\u00f3n de g\u00e9nero, la falta de modelos y mentores, la atenci\u00f3n insuficiente al equilibrio entre trabajo y vida privada y los ambientes de trabajo \u201ct\u00f3xicos\u201d de la industria tecnol\u00f3gica se juntan para crear una tormenta perfecta contra la inclusi\u00f3n de g\u00e9nero.\nAcabar con la brecha de g\u00e9nero en la investigaci\u00f3n sobre IA no tiene f\u00e1cil soluci\u00f3n. Cambios en todo el sistema para crear espacios seguros e inclusivos que apoyen e impulsen a investigadores pertenecientes a grupos con poca representaci\u00f3n, un cambio en las actitudes y las culturas en los campos de la investigaci\u00f3n y la industria y una mejor comunicaci\u00f3n del potencial transformador de la IA en numerosas \u00e1reas podr\u00edan ser parte de la misma.\nHay pruebas de que factores como los estereotipos generalizados de g\u00e9nero y un entorno educativo que afecta m\u00e1s a la confianza de las chicas que a la de los chicos son parte del problema\nLas intervenciones pol\u00edticas, como la inversi\u00f3n estatal de 13,5 millones de libras para fomentar la diversidad de papeles en la IA a trav\u00e9s de nuevos cursos universitarios de transformaci\u00f3n quiz\u00e1 mejorar\u00e1n un poco la situaci\u00f3n, pero se necesitan intervenciones a gran escala para crear mejores conexiones entre las artes, las humanidades y la IA, y cambiar la imagen de qui\u00e9n puede trabajar en IA.\nAunque no hay una sola raz\u00f3n para que las chicas dejen de manera desproporcionada de matricularse en asignaturas como Ciencias, Tecnolog\u00eda, Ingenier\u00eda y Matem\u00e1ticas a medida que avanzan en sus estudios, hay pruebas de que factores como los estereotipos generalizados de g\u00e9nero y un entorno educativo que afecta m\u00e1s a la confianza de las chicas que a la de los chicos son parte del problema. Tambi\u00e9n debemos resaltar aquellos modelos que utilizan la IA para propiciar un cambio a mejor.\nUna intervenci\u00f3n tangible para abordar estos problemas es el Premio Longitude Explorer, que anima a los alumnos de educaci\u00f3n secundaria a utilizar la IA para resolver retos sociales y trabajar con modelos de IA. Queremos que los j\u00f3venes, especialmente las chicas, se den cuenta del potencial de la IA para el bien y de su papel a la hora de impulsar el cambio.\nReforzando la preparaci\u00f3n y la confianza de las j\u00f3venes podemos cambiar la proporci\u00f3n de personas que estudian y trabajan en IA y ayudar a abordar los posibles prejuicios de la inteligencia artificial.\nJuan Mateos-Garcia es director de innovaci\u00f3n y Joysy John es directora de educaci\u00f3n en Nesta\nEste art\u00edculo fue publicado originalmente en The Conversation. Lea el original.\nTraducci\u00f3n de NewsClips.\n\n NEWSLETTER \n Recibe la mejor informaci\u00f3n en tu bandeja de entrada \nUna breve gu\u00eda para que el hombre moderno (o sea, t\u00fa) sepa c\u00f3mo regalar joyas estas navidades evitando compras fallidas de \u00faltima hora y triste desaciertos. Si ya no triunfas regalando, es porque no quieres", "date": "08/23/2019, 19:01:45", "tags": ["Mujeres ciencia", "Cient\u00edficos", "Inteligencia artificial", "Computaci\u00f3n", "Mujeres", "Inform\u00e1tica", "Sociedad", "Industria", "Ciencia"], "newspaper": "elpais"}