{"id": "51d0c03f-24f1-4260-4364-1bb43df9ae2a", "content": "El temor a la inteligencia artificial surge del recelo hacia los intereses econ\u00f3micos\n\nEs un topicazo, cuando se habla de los riesgos de la inteligencia artificial, citar el ejemplo de Skynet, el programa que decide exterminar a los humanos en Terminator. Pero se recuerda muy poco a Cyberdyne Systems, la empresa que lo desarrolla. \u00bfPor qu\u00e9 esta compa\u00f1\u00eda decide poner en marcha un proyecto tan peligroso sin estudiar a fondo las consecuencias? En la \u00faltima d\u00e9cada han surgido numerosos recelos hacia los desarrollos tecnol\u00f3gicos, incluidas las m\u00e1quinas inteligentes, pero sabemos poco sobre c\u00f3mo se construye esta desconfianza. Ahora que se pretende que la inteligencia artificial entre en cada rinc\u00f3n de nuestras vidas, urge conocer cu\u00e1l es la actitud de los ciudadanos ante esta tecnolog\u00eda decisiva. Por primera vez, un estudio ha analizado en detalle las respuestas de una gran muestra de espa\u00f1oles para descubrir por qu\u00e9 desconf\u00edan de las m\u00e1quinas que piensan y parece que la met\u00e1fora de Cyberdyne funciona. Quienes recelan lo hacen, entre otros motivos, porque desconf\u00edan de los intereses econ\u00f3micos que pueda haber detr\u00e1s del desarrollo de estos programas.\nUn tercio cree que tiene m\u00e1s riesgos que beneficios, un 38% opina lo contrario y un 28% considera que est\u00e1n equilibrados\nAl preguntarle a 5.200 espa\u00f1oles sobre la inteligencia artificial se descubre que un tercio cree que tiene m\u00e1s riesgos que beneficios (33,3%), un 38,4% opina lo contrario y un 28,3% considera que riesgos y beneficios est\u00e1n equilibrados. Pero lo m\u00e1s interesante surgi\u00f3 cuando los investigadores, de la Universidad Aut\u00f3noma de Madrid (UAM), analizaron esas respuestas junto con otras que los encuestados dieron sobre otros aspectos generales sobre ciencia y tecnolog\u00eda. Eso les permiti\u00f3 hacer tres asociaciones muy claras entre los recelos que manifiesta estos espa\u00f1oles.\nLa primera es la relaci\u00f3n directa entre esta preocupaci\u00f3n y la que tiene que ver con la privacidad, un asunto que ha alarmado cada vez a m\u00e1s gente en los \u00faltimos a\u00f1os a partir de los numerosos esc\u00e1ndalos de empresas como Facebook y Google. Precisamente, las mismas compa\u00f1\u00edas tecnol\u00f3gicas que en los \u00faltimos a\u00f1os han tomado las riendas en el desarrollo de la inteligencia artificial atendiendo a sus intereses comerciales, como denuncian desde el mundo acad\u00e9mico.\nEsto nos lleva al segundo aspecto que destaca entre quienes desconf\u00edan de las m\u00e1quinas pensantes. \u201cSe da sobre todo entre la gente que ya manifiesta una desconfianza sobre la financiaci\u00f3n de la ciencia, por ejemplo, y que dependiendo de qui\u00e9n paga duda de que la aplicaci\u00f3n final vaya a ser positiva. Son gente que desconf\u00eda del uso que se le pueda dar por los intereses que pueda haber detr\u00e1s\u201d, resume Josep Lobera, autor principal del estudio, que se basa en los datos de la encuesta de Percepci\u00f3n Social de la Ciencia de Fecyt. Las mujeres en general desconf\u00edan m\u00e1s.\n\"Quiz\u00e1s habr\u00eda que alertar al 38% de la poblaci\u00f3n que cree que tiene m\u00e1s beneficios que riesgos sobre los errores e injusticias que causa\", advierte V\u00e9liz\nTambi\u00e9n es llamativo que los colectivos vulnerables no est\u00e9n tan preocupados por las consecuencias negativas de la inteligencia artificial como cabr\u00eda esperar, incluso controlando la variable de la alfabetizaci\u00f3n cient\u00edfica. \u201cLos trabajadores menos especializados, los que est\u00e1n m\u00e1s en riesgo, no tienen una preocupaci\u00f3n proporcional a la situaci\u00f3n de riesgo en la que est\u00e1n. Es como si supi\u00e9ramos que viene una crecida y los que est\u00e1n en la playa est\u00e1n preocupados, pero no tanto como deber\u00edan, en comparaci\u00f3n con quienes est\u00e1n en lo alto de la cumbre\u201d, advierte el soci\u00f3logo de la UAM sobre las conclusiones de su estudio.\nAdem\u00e1s, no se encuentran diferencias con la percepci\u00f3n de la robotizaci\u00f3n, \u201cque se observa como un continuo: es igual un brazo rob\u00f3tico en la Ford que un algoritmo que se escribe una noticia\u201d, afirma Lobera. Y a\u00f1ade: \u201cNo distinguen del todo el concepto de m\u00e1quina inteligente y mantienen actitudes muy similares hacia algoritmos, robotizaci\u00f3n\u2026 todo es lo mismo\u201d.\n\u00bfPor qu\u00e9 Facebook, Google, Amazon y Microsoft gastan millones y millones en inteligencias que ganan al p\u00f3ker para el Pent\u00e1gono y que muestran anuncios en sus plataformas? \u201c\u00bfNos podemos fiar o son como Cyberdyne?\u201d, podr\u00edan preguntarse los ciudadanos que le ponen pegas a esta tecnolog\u00eda. O sobre la pujanza que est\u00e1 adquiriendo China en este campo, con investigaciones mucho m\u00e1s centralizadas.\nPor ese motivo, Carissa V\u00e9liz, especialista en \u00e9tica digital de la Universidad de Oxford, se pregunta c\u00f3mo debemos usar estos resultados para cambiar la sociedad a mejor, porque no es obvio en el caso de una tecnolog\u00eda que est\u00e1 en una fase tan temprana. \u201cSi la encuesta fuera sobre la vacuna para el polio, y 33% de la ciudadan\u00eda pensara que esa tecnolog\u00eda tiene m\u00e1s riesgos que beneficios, estar\u00eda claro qu\u00e9 hacer: campa\u00f1as de informaci\u00f3n\u201d, explica. Pero en este caso, asegura V\u00e9liz, la opini\u00f3n dividida de la ciudadan\u00eda parece alinearse con la divisi\u00f3n existente entre los expertos. \u00bfHabr\u00eda que intentar convencer al 33% de la poblaci\u00f3n de que vale la pena cuando no est\u00e1 claro que sea as\u00ed (por lo menos en esta fase, con las maneras en las que se est\u00e1 implementando)? \u00bfO quiz\u00e1s habr\u00eda que alertar al 38% de la poblaci\u00f3n que cree que tiene m\u00e1s beneficios que riesgos sobre los errores e injusticias que ha causado y sigue causando?\u201d.\n\u201cLos trabajadores menos especializados, los que est\u00e1n m\u00e1s en riesgo, no tienen una preocupaci\u00f3n proporcional a la situaci\u00f3n de riesgo en la que est\u00e1n\", asegura Lobera\nEste es el tipo de pregunta que se hacen los que desconf\u00edan, seg\u00fan los datos de Lobera. \u201cHay una divisi\u00f3n muy clara: igualitaristas frente a individualistas. Los primeros, que se fijan en los riesgos de la inteligencia artificial, est\u00e1n m\u00e1s preocupados por la redistribuci\u00f3n; los segundos por un Estado demasiado intervencionista\u201d, resume. \u201cEst\u00e1n muy afectados por estos valores culturales, es algo muy parecido a lo que sucede con otras tecnolog\u00edas, como la energ\u00eda nuclear\u201d, afirma Lobera.\n\u201c\u00bfLa gente es consciente de que la causa por la que no obtuvo un pr\u00e9stamo, o un trabajo, es por un algoritmo que no ofrece razones? No lo s\u00e9. Lo dudo\u201d, contin\u00faa V\u00e9liz. \u201cY no porque la gente sea tonta o ignorante, sino porque no es f\u00e1cil estar bien informado\u201d, asegura. \u201cPodr\u00edas preguntarle a un experto mundial: \u00bfcu\u00e1ntos algoritmos han tomado decisiones sobre tu vida hoy y c\u00f3mo han llegado a esas decisiones? Incluso esa persona no podr\u00eda contestar la pregunta\u201d, asegura la experta de Oxford. Y denuncia: \u201cEl uso de algoritmos no es algo que se anuncie ni se explique. Son procedimientos a los que la ciudadan\u00eda es sometida de manera opaca\u201d.\nPor su parte, a la experta Nuria Oliver le parece que \u201ctiene sentido\u201d esta resistencia a la entre aquellas personas que expresan una mayor preocupaci\u00f3n sobre la privacidad y la igualdad. Oliver, que form\u00f3 parte del primer grupo de sabios del gobierno espa\u00f1ol en inteligencia artificial y asesora a la Comisi\u00f3n Europea, hace suyas las acciones propuestas en el estudio de Lobera, como mejorar la comunicaci\u00f3n sobre esta tecnolog\u00eda, \u201cevitando el sensacionalismo catastrofista e informando con rigor\u201d, y colaborando con la ciudadan\u00eda para que se sienta involucrada y entienda mejor la tecnolog\u00eda. Y agrega: \u201cYo a\u00f1adir\u00eda inversi\u00f3n en educaci\u00f3n en todos los niveles: educaci\u00f3n obligatoria, introduciendo el pensamiento computacional como asignatura troncal; la educaci\u00f3n a los profesionales, sobre todo a aquellos cuyas profesiones se van a ver afectadas por la inteligencia artificial; educaci\u00f3n a la clase pol\u00edtica, a la ciudadan\u00eda y a los medios de comunicaci\u00f3n\u201d.\n NEWSLETTER \n Recibe el bolet\u00edn de Ciencia \nUna breve gu\u00eda para que el hombre moderno (o sea, t\u00fa) sepa c\u00f3mo regalar joyas estas navidades evitando compras fallidas de \u00faltima hora y triste desaciertos. Si ya no triunfas regalando, es porque no quieres", "date": "11/15/2019, 20:01:45", "tags": ["Algoritmos computacionales", "Rob\u00f3tica", "Automatizaci\u00f3n", "Inteligencia artificial", "Facebook", "Google", "Computaci\u00f3n", "Redes sociales", "Alphabet", "Inform\u00e1tica", "Internet", "Empresas", "Tecnolog\u00eda", "Ciencia"], "newspaper": "elpais"}