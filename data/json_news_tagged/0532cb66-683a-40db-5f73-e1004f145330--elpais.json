{"id": "0532cb66-683a-40db-5f73-e1004f145330", "content": "May\u00fasculas, exclamaciones, emojis, dibujos, im\u00e1genes y v\u00eddeos delatan los bulos\n\nEn torno a una cita casual en un bar salen algunos proyectos interesantes. De una reuni\u00f3n de amigos durante unas copas surgi\u00f3 la misi\u00f3n israel\u00ed a la Luna. Algo parecido ocurri\u00f3 con una reciente investigaci\u00f3n sobre las caracter\u00edsticas de los bulos o fake news en Twitter, una de las principales redes sociales. A Miguel Molina, cient\u00edfico de datos que investigaba en el Imperial College de Londres, mientras conversaba con Juan G\u00f3mez Romero, del departamento de Ciencias de la Computaci\u00f3n de la Universidad de Granada, se le ocurri\u00f3 desarrollar un sistema para detectar los bulos. Sus resultados preliminares detectan patrones de escritura, env\u00edo y comportamiento que abren la puerta a acabar con la plaga de la desinformaci\u00f3n. No obstante, Twitter advierte de las limitaciones de estudios similares.\n\u201cLo primero fue acotar el campo de investigaci\u00f3n y definir fake news\u201d, comenta Molina. \u201cDe forma muy resumida, son mentiras intencionadas que buscan dinero o tr\u00e1fico\u201d, explica. Esa definici\u00f3n coincide con otras de este mismo campo que vinculan la proliferaci\u00f3n de noticias falsas a intentos de desestabilizaci\u00f3n, influencia y monetizaci\u00f3n.\n\u201cUn familiar o un amigo puede pensar que est\u00e1 enviando informaci\u00f3n que cree que es verdadera, pero no tiene intenci\u00f3n en ello\u201d, explica el investigador. Con esta premisa, el equipo, con la colaboraci\u00f3n del Imperial College, comenz\u00f3 a recopilar, anotar y seleccionar tuits que respond\u00edan a su objeto de estudio.\nLa aplicaci\u00f3n de an\u00e1lisis estad\u00edsticos y matem\u00e1ticos sobre el material arroj\u00f3 unas caracter\u00edsticas particulares en la redacci\u00f3n de las fake news: suelen incorporar may\u00fasculas, exclamaciones, emojis (pictogramas), dibujos, im\u00e1genes y v\u00eddeos. \u201cBuscan la sorpresa, llamar la atenci\u00f3n\u201d, argumenta Molina.\nNights of horror in Catalonia. Young pro-independence female activist kidnapped by police in Tarragona pic.twitter.com/HTJ9sXX3cw\nTuit difundido el pasado 22 de octubre en el que, encabezado con la expresi\u00f3n \"Noches de horror en Catalu\u00f1a\", se atribuye a la polic\u00eda el \"secuestro\" (Privaci\u00f3n de libertad ambulatoria a una persona o grupo de personas, exigiendo, a cambio de su liberaci\u00f3n, el cumplimiento de alguna condici\u00f3n, como puede ser el pago de un rescatede) de una \"joven\". Se trata de la detenci\u00f3n de una mujer en Tarragona por los disturbios contra la sentencia del proc\u00e9s. La magistrada del Juzgado de Instrucci\u00f3n 1 de Tarragona, en funciones de guardia, dict\u00f3 orden de prisi\u00f3n provisional sin fianza para la acusada.\nEste comportamiento pretende pescar en aguas de la polarizaci\u00f3n, es decir, \u201cfuncionan porque los destinatarios est\u00e1n dispuesto a creerse las noticias falsas\u201d. Con esa complicidad entre emisor y receptor, la capacidad de penetraci\u00f3n y difusi\u00f3n se multiplica. Su env\u00edo masivo ya consigue el efecto deseado cuando la intenci\u00f3n es la influencia. Si, adem\u00e1s, se quiere conseguir dinero, incluye enlaces para transferir tr\u00e1fico a una determinada web con el fin de monetizar las visitas o atraer compras o pagos.\nEl trabajo, publicado en la revista internacional IEEE Access, analiza matem\u00e1ticamente otras caracter\u00edsticas de los tuits, como los metadatos que identifican la cuenta, el autor, el n\u00famero de seguidores, favoritos, contactos o fecha de registro en la red social.\nTodas estas caracter\u00edsticas, filtradas por un programa inform\u00e1tico, han permitido determinar que las cuentas que comparten informaci\u00f3n err\u00f3nea se crean vinculadas a un episodio (disturbios en Catalu\u00f1a, elecciones, Brexit) concreto de la actualidad. De esta forma, adem\u00e1s de tener m\u00e1s opciones de captar la atenci\u00f3n al sumarse a temas que son tendencia, se benefician de un menor tiempo de los equipos de la red social y ajenos para que sean verificadas.\nTambi\u00e9n han detectado que las cuentas de fake news usan caracteres extra\u00f1os tanto en su nombre como en su descripci\u00f3n, y tienen pocos seguidores, pero s\u00ed siguen a muchos usuarios a los que intentan ganar con su adhesi\u00f3n y que sirvan de correa de transmisi\u00f3n. Este comportamiento, conocido como reciprocidad altruista, permite que \u00abla creaci\u00f3n de enlaces dirigidos a otros nodos impulse a los segundos a corresponder mediante la creaci\u00f3n de un v\u00ednculo con el primero\u00bb, seg\u00fan la investigaci\u00f3n.\nDe esta forma, ya sean creados por robots o por personas, tanto en su creaci\u00f3n como en la estrategia de difusi\u00f3n buscan explotar sesgos humanos conocidos, como el de confirmaci\u00f3n (tendencia a favorecer, buscar y recordar la informaci\u00f3n que confirma las propias creencias) o como el mencionado de reciprocidad altruista.\nEl modelo desarrollado por Molina y G\u00f3mez con la colaboraci\u00f3n del Imperial College permite establecer una clasificaci\u00f3n num\u00e9rica sobre las probabilidades de que el tuit analizado sea un bulo. De esta forma, se puede establecer un c\u00f3digo num\u00e9rico (50% de ser fake news) o de colores (rojo o verde) para advertir al lector de que podr\u00eda encontrarse ante una mentira intencionada.\nLos sistemas actuales de verificaci\u00f3n manual no son capaces de responder a todo el tr\u00e1fico que se genera, circunstancia que aprovechan los propagadores de bulos para inundar las redes. Con un algoritmo matem\u00e1tico, al menos se podr\u00eda preavisar a los usuarios de qu\u00e9 tipo de informaci\u00f3n est\u00e1n recibiendo y las probabilidades de que se trate de una falsedad, explica Molina.\nTwitter advierte de las limitaciones de estos programas\nLa red social ha agradecido la investigaci\u00f3n y reitera que para proyectos similares ponen a disposici\u00f3n del p\u00fablico de forma gratuita los datos de su interfaz de programaci\u00f3n de aplicaciones (API). \"Ning\u00fan otro servicio o plataforma hace esto\", afirman fuentes de la compa\u00f1\u00eda.\nSin embargo, la red social recuerda que su director de Integridad, Yoel Roth, ya ha advertido de los defectos y fallos en la investigaci\u00f3n de bots o mensajes creados de forma autom\u00e1tica. \"Vemos una gran cantidad de investigaciones (...) que realizan evaluaciones exhaustivas de los comportamientos de la cuenta utilizando solo se\u00f1ales p\u00fablicas, como la ubicaci\u00f3n (si se cita), el contenido de la cuenta, la frecuencia de tuits y las cuentas que siguen. Para ser claros: ninguno de estos indicadores es suficiente para determinar la atribuci\u00f3n definitivamente. Buscar cuentas que se parezcan a las divulgadas es un enfoque igualmente defectuoso, dado que muchos de los malos actores imitan las cuentas leg\u00edtimas para parecer cre\u00edbles. Este enfoque tambi\u00e9n a menudo captura err\u00f3neamente las voces leg\u00edtimas que comparten un punto de vista pol\u00edtico particular con el que uno no est\u00e1 de acuerdo\".\n\"Antes de participar en este tipo de investigaci\u00f3n y hacer estas afirmaciones, se deben considerar las normas \u00e9ticas. Hacer lo contrario no promueve el conocimiento p\u00fablico, sino que corre el riesgo de socavar profundamente la confianza en el debate p\u00fablico y la conversaci\u00f3n\", advierte Roth.\n NEWSLETTER \n Recibe la mejor informaci\u00f3n en tu bandeja de entrada \nUna breve gu\u00eda para que el hombre moderno (o sea, t\u00fa) sepa c\u00f3mo regalar joyas estas navidades evitando compras fallidas de \u00faltima hora y triste desaciertos. Si ya no triunfas regalando, es porque no quieres", "date": "11/02/2019, 20:01:45", "tags": ["Fake news", "Twitter", "Manipulaci\u00f3n informativa", "Redes sociales", "Empresas", "Internet", "Medios comunicaci\u00f3n", "Econom\u00eda", "Telecomunicaciones", "Tecnolog\u00eda", "Comunicaci\u00f3n", "Comunicaciones", "Ciencia"], "newspaper": "elpais"}